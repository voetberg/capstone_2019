{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = read_dataset('Digits_X_train.csv', 'Digits_y_train.csv')\n",
    "X_test, y_test = read_dataset('Digits_X_test.csv', 'Digits_y_test.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "    normalize the features\n",
    "    Using normal distribution\n",
    "'''\n",
    "def get_mean_variance(X):\n",
    "    mean = np.mean(X, axis=0) # axis=0: taking means along the\n",
    "    # vertical line (column)\n",
    "    # (sum(x_i-\\mu)^2)/N\n",
    "    X_temp = X - mean #\n",
    "    X_temp_entrypointwise = X_temp*X_temp\n",
    "    variance = np.mean(X_temp_entrypointwise, axis=0) #axis=0: \n",
    "    # taking means along the vertical line (column)\n",
    "    return mean, variance\n",
    "    \n",
    "def normalize_features(X_train, X_test):\n",
    "    mean, variance = get_mean_variance(X_train)\n",
    "    variance += 1e-15\n",
    "    ''' transform the feature '''\n",
    "    X_train_norm = (X_train - mean)/np.sqrt(variance)\n",
    "    #math.sqrt doesnot work for numpy\n",
    "    X_test_norm = (X_test - mean)/np.sqrt(variance)\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "X_train_norm, X_test_norm = normalize_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not need to add bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find common labels\n",
    "def find_common_labels(labels):\n",
    "    most_common_label = Counter(labels).most_common(1)\n",
    "    return most_common_label[0][0]\n",
    "# label_list = [0, 1, 0, 3, 2, 0, 1, 0, 2, 3]\n",
    "# find_common_labels(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get Distance\n",
    "def k_NN_EuclideanDistance(X, point, k):\n",
    "    distance = ???\n",
    "    k_NN_indices = ???\n",
    "    return k_NN_indices\n",
    "\n",
    "def predict_label(X_train, y_train, X_test, k):\n",
    "    n_test_samples = X_test.shape[0]\n",
    "    y_pred = []\n",
    "    for i in range(n_test_samples):\n",
    "        test_point = X_test[i]\n",
    "        k_NN_indices = ???\n",
    "        k_NN_labels = ???\n",
    "        # print(type(k_NN_labels))\n",
    "        pred_label = find_common_labels(k_NN_labels)\n",
    "        y_pred.append(pred_label)\n",
    "    return np.asarray(y_pred, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your own score for k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe\n",
    "# label is 0 -> [1 0 0 0 0 0 0 0 0]\n",
    "# label is 3 -> [0 0 0 1 0 0 0 0 0]\n",
    "y_train_ohe, y_test_ohe = one_hot_encoder(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define predicor scores (or probability matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictor_scores(X_train, y_train, X_test, k):\n",
    "    '''\n",
    "        y_train: one_hot_encoder format\n",
    "    '''\n",
    "    n_test_samples = X_test.shape[0]\n",
    "    y_pred = []\n",
    "    n_classes= y_train.shape[1]\n",
    "    probability_matrix = np.zeros((n_test_samples, n_classes))\n",
    "    for i in range(n_test_samples):\n",
    "        test_point = X_test[i]\n",
    "        k_NN_indices = k_NN_EuclideanDistance(X_train, test_point, k)\n",
    "        k_NN_labels = y_train[k_NN_indices]\n",
    "        for class_id in range(n_classes):\n",
    "            ohe_labels = k_NN_labels[:, class_id]\n",
    "            num_zeros = (ohe_labels == 0).sum()\n",
    "            num_ones =  (ohe_labels == 1).sum()\n",
    "            probability_matrix[i, class_id] = num_ones/(num_zeros + num_ones)\n",
    "    return probability_matrix\n",
    "probability_matrix = get_predictor_scores(X_train_norm, y_train_ohe, X_test_norm, 3)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test_ohe)\n",
    "# print(probability_matrix)\n",
    "def predict_binary_label(score, threshold):\n",
    "    label = np.copy(score)\n",
    "    label[label >= threshold] = 1\n",
    "    label[label < threshold] = 0\n",
    "    return label\n",
    "\n",
    "def get_confusion_matrix(predictor_score, true_labels):\n",
    "    '''\n",
    "        true_lables: binary labels (0 and 1)\n",
    "    '''\n",
    "    # step1 change threshold from 1 to 0\n",
    "    # step2 get predicted labels\n",
    "    # step3 compare pred ones to true ones -> TN, TF, FN, FP\n",
    "    TNR_list = []\n",
    "    TPR_list = []\n",
    "    FNR_list = []\n",
    "    FPR_list = []\n",
    "    for i in range(100, -1, -1):\n",
    "        threshold = i/100;\n",
    "        pred_labels = predict_binary_label(predictor_score, threshold)\n",
    "        # compare between pred_labels and true_labels\n",
    "        #use np.logical_and to calculate\n",
    "        TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0)) \n",
    "        FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0)) \n",
    "        FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1)) \n",
    "        TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1)) \n",
    "        TNR = TN/(TN+FP)\n",
    "        FPR = FP/(TN+FP)\n",
    "        FNR = FN/(FN+TP)\n",
    "        TPR = TP/(FN+TP)\n",
    "        TNR_list.append(TNR)\n",
    "        FPR_list.append(FPR)\n",
    "        FNR_list.append(FNR)\n",
    "        TPR_list.append(TPR)\n",
    "    return TNR_list, FPR_list, FNR_list, TPR_list\n",
    "\n",
    "def plot_ROC_curve(FPR_list, TPR_list):\n",
    "    plt.plot(FPR_list, TPR_list, color='g', lw=2) # roc curve\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # diagonal line\n",
    "    plt.xlim([0, 1.01]) # set the limits of x-axis\n",
    "    plt.ylim([0, 1.01]) # set the limiets of y-axis\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')    \n",
    "#     plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def ROC_curve(FPR_list, TPR_list):\n",
    "    '''\n",
    "        convert the rates to the staircase effect\n",
    "    '''\n",
    "    FPR_ROC = []\n",
    "    TPR_ROC = []\n",
    "    for i in range(len(FPR_list)-1):\n",
    "        FPR_ROC.append(FPR_list[i])\n",
    "        TPR_ROC.append(TPR_list[i])\n",
    "        FPR_ROC.append(FPR_list[i+1])\n",
    "        TPR_ROC.append(TPR_list[i])\n",
    "    ## toFIX: add the two last points\n",
    "    FPR_ROC.append(FPR_list[-1])\n",
    "    TPR_ROC.append(TPR_list[-2])\n",
    "    FPR_ROC.append(FPR_list[-1])\n",
    "    TPR_ROC.append(TPR_list[-1])\n",
    "    return FPR_ROC, TPR_ROC # get staircase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.971\n"
     ]
    }
   ],
   "source": [
    "def accuracy(ypred, yexact):\n",
    "   ????\n",
    "print(\"Accuracy = %.3f\" % accuracy(y_pred, y_test.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
