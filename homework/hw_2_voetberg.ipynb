{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in(feat,label): \n",
    "    ##Simple read function\n",
    "    df_x = pd.read_csv(feat)\n",
    "    x = df_x.values\n",
    "    \n",
    "    df_y = pd.read_csv(label)\n",
    "    y = df_y.values\n",
    "    return x,y\n",
    "\n",
    "def mean_var(x): \n",
    "    '''Returns mean and variance of a set x'''\n",
    "    ##Calculate avg, use axis=0 to take it along the values, not the features\n",
    "    mu = np.mean(x,axis=0)\n",
    "    std = np.mean((x - mu)*(x - mu), axis=0)\n",
    "    return mu,std\n",
    "\n",
    "def normalize(train,test): \n",
    "    '''Function calling both testing and training sets, \n",
    "    must be normalized by the mean and variance\n",
    "    Normalize such that X = (X - mean)/sqrt(Var)'''\n",
    "    ##Call the mean_var function\n",
    "    mu,std = mean_var(train)\n",
    "    ##Normalize\n",
    "    train_norm = (train - mu)/(np.sqrt(std) +1e-15) ## 1e-15 added to avoid divide by 0 error\n",
    "    test_norm = (test - mu)/(np.sqrt(std) +1e-15)\n",
    "    return train_norm,test_norm\n",
    "\n",
    "def add_bias(X): \n",
    "    '''Adds a bias term to make sure we don't fuck up the model too bad'''\n",
    "    X_ones = np.ones(X.shape[0])\n",
    "    X_ones = X_ones.reshape(-1,1)\n",
    "    return np.append(X_ones,X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##These are all the data processing cells. No actual modeling is done here\n",
    "pwd = \"./data/HW2_data/HW2_data/\"\n",
    "x_train, y_train = read_in(pwd+\"X_iris_train.csv\",pwd+\"y_iris_train.csv\")\n",
    "x_test, y_test = read_in(pwd+\"X_iris_test.csv\",pwd+\"y_iris_test.csv\")\n",
    "n_sample,n_feat = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n",
      "(112, 1)\n",
      "(38, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm,x_test_norm = normalize(x_train,x_test)\n",
    "x_train_norm_c0,x_test_norm_c0 = add_bias(x_train_norm),add_bias(x_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of logistic regression, the predictor is a sigmoid function, that returns a probablity of being either 0 or 1. It is then given a cut off value where if above this threshold it is assigned 1, otherwise it is assigned 0. The sigmoid itself is of the form: \n",
    "\n",
    "$$\n",
    "\\frac{1}{1+e^{-X*c_n}}\n",
    "$$\n",
    "\n",
    "Where X is the value being predicted and $c_n$ are the calculated coeffients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(x,c):\n",
    "    '''Uses a sigmoid function to predict\n",
    "    Requires that you calculate optimal coeffs\n",
    "    Returns array of predicted values'''\n",
    "    return 1/(1+np.exp(-x.dot(c)))\n",
    "\n",
    "def loss(x,c,y): \n",
    "    '''Loss function for a gradient descent predictor\n",
    "    This will be minimized using gradient descent\n",
    "    L(c) = 1/M*Sum(y*log(p_c)-(1-y)*log(1-p_c))\n",
    "    Designed to maximize when p_c = 1, minimize when p_c = 0\n",
    "    Returns real value'''\n",
    "    pred = result(x,c)\n",
    "    s = np.sum(-y.T.dot(np.log(pred))-((1-y.T)).dot(np.log(1-pred)))\n",
    "    return 1/x.shape[0]*s\n",
    "\n",
    "def gradient_desc(X,y,l_rate=.01,ite=100,): \n",
    "    '''Input: \n",
    "    X-> Features (NxM), normalized w bias\n",
    "    y->Labels (Nx1)\n",
    "    learning rate (<<.01)\n",
    "    Iterations->Number of times to run \n",
    "    \n",
    "    Output: \n",
    "    c_n->Optimal coeffs\n",
    "    loss->loss value based off \n",
    "    '''\n",
    "    n_feat = X.shape[1] ##N value \n",
    "    c_n = np.zeros((n_feat,1)) ##initialize an empty matrix \n",
    "    loss_range = [0]*ite ##Empty matrix to document how loss changes with iteration\n",
    "    for i in range(ite): \n",
    "        ##Calculate the gradient over a range\n",
    "        ##Gradient of the loss function, this is the simplified version \n",
    "        ## dL/dc = X^t*(y_pred-y_true)\n",
    "        grad = (1/X.shape[0])*(X.T).dot(result(X,c_n)-y)\n",
    "        c_n -=l_rate*grad\n",
    "        loss_range[i] = (loss(X,c_n,y)).ravel()\n",
    "        \n",
    "    return c_n, loss_range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##These cells contain the functions that define the accuracy, and assign true labels to the output of the predictor\n",
    "\n",
    "def acc(y_pre,y_true): \n",
    "    p = np.array(y_pre == y_true, dtype = int)\n",
    "    return np.sum(p)/float(len(y_true))\n",
    "\n",
    "def label_out(y_pre, threshold=.5): \n",
    "    label = np.copy(y_pre)\n",
    "    label[label>threshold ] = 1\n",
    "    label[label<threshold] = 0 \n",
    "    return label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Accuracy: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "c, loss = gradient_desc(x_train_norm_c0, y_train, ite = 50, l_rate = 0.1)\n",
    "y_predict = result(x_test_norm_c0,c) \n",
    "## The label function is applied here so that the accuracy function actually you know. Works. \n",
    "y_predict_true = label_out(y_predict)\n",
    "print(\"True Accuracy:\", acc(y_predict_true,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
