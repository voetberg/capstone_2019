{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Going to use the log regress code for the actual model\n",
    "def read_dataset(feature_file, label_file):\n",
    "    ''' Read data set in *.csv to data frame in Pandas'''\n",
    "    df_X = pd.read_csv(feature_file)\n",
    "    df_y = pd.read_csv(label_file)\n",
    "    X = df_X.values # convert values in dataframe to numpy array (features)\n",
    "    y = df_y.values # convert values in dataframe to numpy array (label)\n",
    "    return X, y\n",
    "\n",
    "def get_mean_variance(X):\n",
    "    mean = np.mean(X, axis=0) # axis=0: taking means along the\n",
    "    # vertical line (column)\n",
    "    # (sum(x_i-\\mu)^2)/N\n",
    "    X_temp = X - mean #\n",
    "    X_temp_entrypointwise = X_temp*X_temp\n",
    "    variance = np.mean(X_temp_entrypointwise, axis=0) #axis=0: \n",
    "    # taking means along the vertical line (column)\n",
    "    return mean, variance\n",
    "    \n",
    "def normalize_features(X_train, X_test):\n",
    "    mean, variance = get_mean_variance(X_train)\n",
    "    variance += 1e-15\n",
    "    ''' transform the feature '''\n",
    "    X_train_norm = (X_train - mean)/np.sqrt(variance)\n",
    "    #math.sqrt doesnot work for numpy\n",
    "    X_test_norm = (X_test - mean)/np.sqrt(variance)\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "def add_column_one(X):\n",
    "    '''\n",
    "         convert X -> [1 X]\n",
    "    '''\n",
    "    # add  column of ones\n",
    "    ones = np.ones(X.shape[0])\n",
    "    ones = ones.reshape(-1, 1)\n",
    "    X_new = np.append(ones, X, axis=1)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "def predictor(X, c):\n",
    "    ''' sigmoid function '''\n",
    "    return 1.0/(1.0 + np.exp(-X.dot(c)))\n",
    "\n",
    "def loss(y_exact, y_pred):\n",
    "    return (-y_exact.T.dot(np.log(y_pred+1e-15))- (1.0 - y_exact).T.dot(np.log(1-y_pred+1e-15)))/float(len(y_exact))\n",
    "\n",
    "def gradient_descent(X, y, epochs=1000, learning_rate=0.0001):\n",
    "    '''\n",
    "        Input\n",
    "        -----\n",
    "        X: training features (normalized and having bias)\n",
    "        y: labels\n",
    "        \n",
    "        output\n",
    "        ------\n",
    "        c: optimal coeffs\n",
    "        loss_history\n",
    "    '''\n",
    "    loss_history = [0]*epochs\n",
    "    c_dim = X.shape[1]\n",
    "    n_samples = X.shape[0]\n",
    "    c = np.ones((c_dim, 1))\n",
    "    print(y.shape)\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predictor(X, c)\n",
    "        \n",
    "        loss_history[epoch] = loss(y_pred, y).ravel()[0] # (2D) (1,1) -> 1D\n",
    "                                                               # [5] -> 5\n",
    "       \n",
    "        XT = X.T\n",
    "        gradient = XT.dot(y_pred-y)/float(n_samples)   \n",
    "        # updating coeffs upon the gradient change\n",
    "        c = c - learning_rate*gradient\n",
    "    return c, loss_history\n",
    "\n",
    "def one_hot_encoder(y_train, y_test):\n",
    "    ''' convert label to a vector under one-hot-code fashion '''\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    y_train_ohe = lb.transform(y_train)\n",
    "    y_test_ohe = lb.transform(y_test)\n",
    "    return y_train_ohe, y_test_ohe\n",
    "\n",
    "def multilabel_train(X, y):# y_train: one_hot_encoder labels\n",
    "    # y_train will have 3 columns\n",
    "    c_list = []\n",
    "    for i in range(y.shape[1]): # 3 columns \n",
    "        y_one_column = y[:, i].reshape(-1, 1) # pick ith columns\n",
    "        c_one_column, loss_history = gradient_descent(X, y_one_column, epochs=10000, learning_rate=0.9)\n",
    "        plot_loss(loss_history)\n",
    "        c_list.append(c_one_column)\n",
    "    return c_list\n",
    "\n",
    "\n",
    "def multilabel_prediction(c_list, X):\n",
    "    i = 0\n",
    "    for c in c_list:\n",
    "        probability = predictor(X, c)\n",
    "        # probabily of one column\n",
    "        if i == 0:\n",
    "            probability_matrix = probability\n",
    "        else:\n",
    "            # combine all decision columns to form a matrix\n",
    "            probability_matrix = np.concatenate(\n",
    "                              (probability_matrix, probability),\n",
    "                               axis=1)\n",
    "        i += 1\n",
    "    labels = [0, 1, 2]\n",
    "    n_samples = X.shape[0]\n",
    "    # find which index gives us the highest probability\n",
    "    y_pred = np.zeros(n_samples, dtype=int) \n",
    "    for i in range(n_samples):\n",
    "        y_pred[i] = labels[np.argmax(probability_matrix[i,:])]\n",
    "    return y_pred, probablity_matrix\n",
    "\n",
    "def label_out(y_pre, threshold=.5): \n",
    "    label = np.copy(y_pre)\n",
    "    label[label>threshold ] = 1\n",
    "    label[label<threshold] = 0 \n",
    "    return label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_dataset('X_iris_train.csv', 'y_iris_train.csv')\n",
    "X_test, y_test = read_dataset('X_iris_test.csv', 'y_iris_test.csv')\n",
    "X_train_norm, X_test_norm = normalize_features(X_train, X_test)\n",
    "X_train_norm_new = add_column_one(X_train_norm)\n",
    "X_test_norm_new = add_column_one(X_test_norm)\n",
    "\n",
    "y_train_ohe, y_test_ohe = one_hot_encoder(y_train, y_test)\n",
    "c_list = multilabel_train(X_train_norm_new, y_train_ohe)\n",
    "\n",
    "y_pred,prob_matrix = multilabel_prediction(c_list, X_test_norm_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##All the metric stuff \n",
    "\n",
    "def get_con_matrix(score, true_label): \n",
    "    '''True: OHE test values \n",
    "    Prob: \n",
    "    ''' \n",
    "    ##Go through threshold on range of 0 to 1 \n",
    "    ##Compare predicted to true values for each threshold \n",
    "        ##Get TP, FP, FN, TN\n",
    "    for i in range(101,-1,-1): \n",
    "        thresh = i/100    \n",
    "        ##Compare predicted to true values for each threshold \n",
    "        pre_label = label_out(score, thresh)\n",
    "        ##Get TP, FP, FN, TN\n",
    "        ##Use np.logical_and to get tn, ft, fp, tp\n",
    "        TNR_lst.append(tn/(tn+ft))\n",
    "        FPR_lst.append(fp/(tn+fp))\n",
    "        FNR_lst.append( fn/(fn+tp))\n",
    "        TPR_lst.append(tp/(fn+tp))\n",
    "    return TNR_lst, FPR_lst,FNR_lst,TPR_lst\n",
    "\n",
    "def ROC_curve(prob_matrix[:1], true_label)\n",
    "    TNR,FPR,FNR,TPR = get_con_matrix(prob_matrix,true_label)\n",
    "    return fpr_ROC, tpr_ROC ##Get staircase, not the curve\n",
    "\n",
    "def AUC(fpr_roc, tpr_roc):\n",
    "    ##Return Area of the ROC curve\n",
    "    return area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
